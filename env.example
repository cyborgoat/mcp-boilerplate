# LLM API Configuration (OpenAI-compatible)
LLM_API_KEY=your_api_key_here
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4o-mini

# Example configurations for different providers:
# OpenAI: LLM_BASE_URL=https://api.openai.com/v1, LLM_MODEL=gpt-4o-mini
# Qwen: LLM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1, LLM_MODEL=qwen-turbo
# Claude: LLM_BASE_URL=https://api.anthropic.com/v1, LLM_MODEL=claude-3-sonnet
# Groq: LLM_BASE_URL=https://api.groq.com/openai/v1, LLM_MODEL=llama-3.1-70b-versatile

# Optional: Logging configuration (loaded via python-dotenv)
DEBUG=false
# LOG_LEVEL options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Use WARNING or ERROR to suppress most logs (recommended: ERROR for quiet operation)
LOG_LEVEL=INFO 